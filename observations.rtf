{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf760
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Bold;\f2\fnil\fcharset0 Menlo-Regular;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 t1 = "a quick brown dog jumps over the lazy fox"\
t2 = "a quick brown fox jumps over the lazy dog"\
t2\'92 = "jumps over the lazy fox is a quick brown dog"\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b \cf0 similarity between t1 and t2
\f0\b0 \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f2\fs22 \cf2 \cb3 \CocoaLigature0 ssv  0.948683298051\
wo  0.568907541281
\f0\fs24 \cf0 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
dpss	   
\f2\fs22 \cf2 \CocoaLigature0 0.333075783753\
\

\f1\b\fs24 similarity between t1 and t2\'92
\f2\b0\fs22 \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 ssv  0.948683298051\
wo  0.509346618537\
\
dpss  0.472750112484\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b \cf2 Best Result So far
\f2\b0 \
\
SSV  WO\
0.8 0.2\
\
Thresh = 0.56\
\
accuracy = 0.712209302326\
\

\f1\b Best result update\
Dec 26, 2016
\f2\b0 \
\
W2V Miss numpy.Random.rand\
\
SSV	  WO\
0.78  0.22\
\
Thresh = 0.559\
\
Accuracy = 0.713178294574\
\
true_positive 2646.0\
false_negative 204.0\
true_negative 298.0\
false_positive 980.0\
precision 0.72972972973\
recall 0.928421052632\
F1 0.817171093267\
accuracy 0.713178294574\
\
\
0 0.45 0.698072548785\
0 0.47 0.699628875853\
0 0.49 0.702023225189\
0 0.5 0.703579552257\
0 0.51 0.706452771459\
0 0.52 0.708009098527\
0 0.53 0.708009098527\
0 0.54 0.709804860529\
0 0.55 0.709325990662\
0 0.56 0.709924577996\
0 0.58 0.702861247456\
0 0.6 0.699988028253\
\
\
Tests on Dec 27\
\
12 = [0.3,0.3,0.4]\
10 = [0,0.4,0.6]\
---------------------------------------\
Weight = 4\
12 0.49\
0.711967054264\
---------------------------------------\
Weight = 6\
12 0.5\
0.71390503876\
---------------------------------------\
Weight = 2\
10 0.44\
0.711724806202\
---------------------------------------\
Weight = 8\
12 0.5\
0.714147286822
\f1\b \
\
\
Results on Dec 30\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f2\b0 \cf2 4076 1725 5801\
tp  3674\
tn  1082\
fp  819\
fn  226\
accuracy  0.819858645061\
F1  0.875491480996\
precision 0.817716447808\
recall  0.942051282051\
\
\'97 ^^^ wrong results ^^^ \'97\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b \cf2 Results on Jan 6\
\
SVM\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f2\b0 \cf2 X.append([float(each[3])*0.80 + float(each[1])*0.20, float(each[5]), float(each[6]), float(each[8]),float(each[9]),float(each[10]),float(each[11]),\
        float(each[18]), float(each[1]), float(each[2])])\
\
tp  1018\
tn  261\
fp  317\
fn  129\
accuracy  0.741449275362\
F1  0.820306204674\
precision 0.762546816479\
recall  0.887532693984\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b \cf2 \
Results on Jan 9\
\
NN 
\f2\b0 MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 6), random_state=0, activation='relu')
\f1\b \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f2\b0 \cf2 X.append([ float(each[5]), float(each[6]), float(each[8]),float(each[9]),float(each[10]),float(each[11]),\
        float(each[18]), float(each[1]), float(each[2]), float(each[19]) ])\
\
\
\
tp  992\
tn  321\
fp  257\
fn  155\
accuracy  0.76115942029\
F1  0.828046744574\
precision 0.794235388311\
recall  0.864864864865\
\
NN\
\
X.append([float(each[3])*0.80 + float(each[1])*0.20, float(each[5]), float(each[6]), float(each[8]),float(each[9]),float(each[10]),float(each[11]),\
        float(each[18]), float(each[2]), float(each[19]), float(each[20]), float(each[21]) ])\
\
tp  998\
tn  336\
fp  242\
fn  149\
accuracy  0.773333333333\
F1  0.836196062003\
precision 0.804838709677\
recall  0.870095902354\
\
10- consecutive test\
\
0.76231884058\
0.751884057971\
0.761739130435\
0.75768115942\
0.773333333333}